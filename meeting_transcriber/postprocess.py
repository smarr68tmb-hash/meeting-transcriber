# -*- coding: utf-8 -*-
"""
–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: —É–¥–∞–ª–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π Whisper.

Whisper —á–∞—Å—Ç–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä—É–µ—Ç –Ω–∞ —Ç–∏—à–∏–Ω–µ –∏–ª–∏ —à—É–º–∞—Ö, –¥–æ–±–∞–≤–ª—è—è:
- "–°—É–±—Ç–∏—Ç—Ä—ã –æ—Ç Amara.org"
- "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç"
- "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä"
- –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
- –ò –¥—Ä—É–≥–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
"""

import re
from typing import List, Dict, Any, Optional

from .logging_setup import get_logger

logger = get_logger()


# === –ü–ê–¢–¢–ï–†–ù–´ –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô ===
# –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–∏–ø–∏—á–Ω—ã—Ö –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π Whisper

HALLUCINATION_PATTERNS = [
    # –°—É–±—Ç–∏—Ç—Ä—ã –∏ —Ç–∏—Ç—Ä—ã
    r"—Å—É–±—Ç–∏—Ç—Ä\w*\s*(–æ—Ç|by|—Å–æ–∑–¥–∞–Ω\w*|–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω\w*)?\s*(amara|youtube|google)?",
    r"subtitl\w*\s*(by|from)?\s*(amara|youtube)?",
    r"—Ç–∏—Ç—Ä\w*\s*(–æ—Ç|by)?",
    
    # –û–∫–æ–Ω—á–∞–Ω–∏—è –≤–∏–¥–µ–æ
    r"–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ\s+—Å–ª–µ–¥—É–µ—Ç",
    r"to\s+be\s+continued",
    r"–∫–æ–Ω–µ—Ü\s*(—Ñ–∏–ª—å–º–∞|—Å–µ—Ä–∏–∏|—ç–ø–∏–∑–æ–¥–∞)?",
    r"the\s+end",
    
    # –ü—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é (YouTube)
    r"–ø–æ–¥–ø–∏—Å—ã–≤–∞\w+\s*(–Ω–∞)?\s*(–∫–∞–Ω–∞–ª)?",
    r"(—Å—Ç–∞–≤—å\w*|–ø–æ—Å—Ç–∞–≤—å\w*)\s*(–ª–∞–π–∫\w*|–ø–∞–ª–µ—Ü)",
    r"subscribe\s*(to)?\s*(the)?\s*(channel)?",
    r"like\s*(and)?\s*subscribe",
    r"–Ω–µ\s+–∑–∞–±—É–¥\w+\s+(–ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è|–ª–∞–π–∫)",
    
    # –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏
    r"—Å–ø–∞—Å–∏–±–æ\s+(–∑–∞\s+)?(–ø—Ä–æ—Å–º–æ—Ç—Ä|–≤–Ω–∏–º–∞–Ω–∏–µ|–ø–æ–¥–ø–∏—Å–∫—É)",
    r"thanks?\s+(for\s+)?(watching|viewing)",
    r"thank\s+you\s+(for\s+)?(watching|viewing)",
    
    # –ú—É–∑—ã–∫–∞–ª—å–Ω—ã–µ –≤—Å—Ç–∞–≤–∫–∏
    r"^\s*‚ô™+\s*$",
    r"^\s*\[–º—É–∑—ã–∫–∞\]\s*$",
    r"^\s*\[music\]\s*$",
    r"^\s*\(–º—É–∑—ã–∫–∞\)\s*$",
    r"^\s*–º—É–∑—ã–∫–∞\s*$",
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
    r"^\s*\.\.\.\s*$",
    r"^\s*‚Ä¶\s*$",
    r"www\.\w+\.\w+",  # URL-–ø–æ–¥–æ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    
    # –ü—É—Å—Ç—ã–µ –∏–ª–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    r"^\s*[.„ÄÇ,ÿå„ÄÅ]+\s*$",
    r"^\s*\?\s*$",
    r"^\s*!\s*$",
]

# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
COMPILED_PATTERNS = [
    re.compile(p, re.IGNORECASE | re.UNICODE) 
    for p in HALLUCINATION_PATTERNS
]


def is_hallucination(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–µ–π.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        True –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂ –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—é
    """
    if not text or not text.strip():
        return True
    
    text_clean = text.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
    for pattern in COMPILED_PATTERNS:
        if pattern.search(text_clean):
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–∞ –∞ –∞ –∞ –∞")
    words = text_clean.split()
    if len(words) >= 3:
        unique_words = set(w.lower() for w in words)
        # –ï—Å–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
        if len(unique_words) == 1 and len(words) >= 3:
            return True
    
    return False


def is_repeated_segment(
    current_text: str, 
    previous_texts: List[str], 
    threshold: float = 0.9
) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–µ–≥–º–µ–Ω—Ç –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö.
    
    Args:
        current_text: –¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç
        previous_texts: –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N)
        threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)
        
    Returns:
        True –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —è–≤–ª—è–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º
    """
    if not current_text or not previous_texts:
        return False
    
    current_clean = current_text.strip().lower()
    if len(current_clean) < 5:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        return False
    
    for prev in previous_texts:
        prev_clean = prev.strip().lower()
        if not prev_clean:
            continue
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if current_clean == prev_clean:
            return True
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–æ–¥–∏–Ω —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º)
        if current_clean in prev_clean or prev_clean in current_clean:
            shorter = min(len(current_clean), len(prev_clean))
            longer = max(len(current_clean), len(prev_clean))
            if shorter / longer >= threshold:
                return True
    
    return False


def filter_hallucinations(
    segments: List[Dict[str, Any]],
    check_repeats: bool = True,
    repeat_window: int = 3
) -> List[Dict[str, Any]]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤.
    
    Args:
        segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        check_repeats: –ü—Ä–æ–≤–µ—Ä—è—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–µ–≥–º–µ–Ω—Ç—ã
        repeat_window: –°–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞ –ø–æ–≤—Ç–æ—Ä—ã
        
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    """
    if not segments:
        return segments
    
    filtered = []
    removed_count = 0
    previous_texts: List[str] = []
    
    for seg in segments:
        text = seg.get("text", "").strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—é
        if is_hallucination(text):
            removed_count += 1
            logger.debug(f"–£–¥–∞–ª–µ–Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è: '{text[:50]}...'")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ
        if check_repeats and is_repeated_segment(text, previous_texts):
            removed_count += 1
            logger.debug(f"–£–¥–∞–ª—ë–Ω –ø–æ–≤—Ç–æ—Ä: '{text[:50]}...'")
            continue
        
        # –°–µ–≥–º–µ–Ω—Ç –ø—Ä–æ—à—ë–ª —Ñ–∏–ª—å—Ç—Ä—ã
        filtered.append(seg)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–∫–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        previous_texts.append(text)
        if len(previous_texts) > repeat_window:
            previous_texts.pop(0)
    
    if removed_count > 0:
        logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π/–ø–æ–≤—Ç–æ—Ä–æ–≤: {removed_count}")
    
    return filtered


def clean_text(text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not text:
        return text
    
    # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = re.sub(r'\s+([.,!?;:])', r'\1', text)
    
    # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = re.sub(r'([.,!?])\1+', r'\1', text)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    text = text.strip()
    
    return text


def postprocess_transcription(
    result: Dict[str, Any],
    filter_enabled: bool = True
) -> Dict[str, Any]:
    """
    –ü–æ–ª–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
    
    Args:
        result: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (text, segments)
        filter_enabled: –í–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """
    if not result:
        return result
    
    segments = result.get("segments", [])
    
    if filter_enabled and segments:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
        segments = filter_hallucinations(segments)
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–∞–∂–¥–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ
        for seg in segments:
            if "text" in seg:
                seg["text"] = clean_text(seg["text"])
        
        # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
        full_text = " ".join(
            seg.get("text", "").strip() 
            for seg in segments 
            if seg.get("text", "").strip()
        )
        full_text = clean_text(full_text)
        
        result["segments"] = segments
        result["text"] = full_text
    
    return result

